{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第1章: 準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00. 文字列の逆順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"stressed\"\n",
    "s[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01. 「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"パタトクカシーー\"\n",
    "s[0:-1:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['パ', 'タ', 'ト', 'ク', 'カ', 'シ', 'ー', 'ー']\n"
     ]
    }
   ],
   "source": [
    "s = \"パトカー\"\n",
    "t = \"タクシー\"\n",
    "u = []\n",
    "for i in range(len(s) + len(t)):\n",
    "    if i % 2 == 0:\n",
    "        u += s[int(i / 2)]\n",
    "    else:\n",
    "        u += t[int((i-1) / 2)]\n",
    "print(u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03. 円周率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314159265358979"
     ]
    }
   ],
   "source": [
    "sentence = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "alphabet_only_sentence = sentence.replace(',', '').replace('.', \"\")\n",
    "words = alphabet_only_sentence.split(sep=\" \")\n",
    "words_length = list(map(lambda x: len(x), words))\n",
    "for i in range(len(words)):\n",
    "    # print(f\"{words[i]}:\", end=\" \")\n",
    "    print(f\"{words_length[i]}\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04. 元素記号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "alphabet_only_sentence = sentence.replace(',', '').replace('.', \"\")\n",
    "words = alphabet_only_sentence.split(sep=\" \")\n",
    "dic = {}\n",
    "for i in range(len(words)):\n",
    "    if i in [0, 4, 5, 6, 7, 8, 14, 15, 18]:\n",
    "        dic[words[i][0]] = i+1\n",
    "    else:\n",
    "        dic[words[i][:2]] = i+1\n",
    "print(dic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 05. n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2-gram (unit=word)\n",
      "'Iam' 'aman' 'anNLPer' \n",
      "start 2-gram (unit=character)\n",
      "'Ia' 'am' 'ma' 'an' 'nN' 'NL' 'LP' 'Pe' 'er' \n"
     ]
    }
   ],
   "source": [
    "def ngram(sequence, n, unit):\n",
    "    print(f\"start {n}-gram (unit={unit})\")\n",
    "\n",
    "    # convert sentence type words list to string\n",
    "    if type(sequence) == \"list\":\n",
    "        sequence = \" \".join(sequence)\n",
    "\n",
    "    alphabet_only_sequence = sequence.replace(',', '').replace('.', \"\")\n",
    "    gram_unit = alphabet_only_sequence.split(sep=\" \")\n",
    "    if unit==\"character\":\n",
    "        gram_unit = ''.join(gram_unit)\n",
    "\n",
    "    ngrams = []\n",
    "    for i in range(len(gram_unit)-1):\n",
    "        ngrams.append(f\"{gram_unit[i]}{gram_unit[i+1]}\")\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "sentence = \"I am an NLPer\"\n",
    "\n",
    "ngrams = ngram(sentence, n=2, unit=\"word\")\n",
    "for i in range(len(ngrams)):\n",
    "    print(f\"'{ngrams[i]}'\", end=\" \")\n",
    "print()\n",
    "\n",
    "ngrams = ngram(sentence, n=2, unit=\"character\")\n",
    "\n",
    "for i in range(len(ngrams)):\n",
    "    print(f\"'{ngrams[i]}'\", end=\" \")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 06. 集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start 2-gram (unit=character)\n",
      "start 2-gram (unit=character)\n",
      "XとYの和集合: {'ap', 'ag', 'ar', 'is', 'ad', 'pa', 'ra', 'gr', 'ph', 'se', 'di'}\n",
      "XとYの積集合: {'ra', 'pa', 'ar', 'ap'}\n",
      "XとYの差集合: {'ad', 'se', 'di', 'is'}\n",
      "seはXに含まれる\n",
      "seはYに含まれない\n"
     ]
    }
   ],
   "source": [
    "s = \"paraparaparadise\"\n",
    "t = \"paragraph\"\n",
    "\n",
    "X = ngram(s, n=2, unit=\"character\")\n",
    "Y = ngram(t, n=2, unit=\"character\")\n",
    "\n",
    "set_X = set(X)\n",
    "set_Y = set(Y)\n",
    "\n",
    "print(f\"XとYの和集合: {set_X.union(set_Y)}\")\n",
    "print(f\"XとYの積集合: {set_X.intersection(set_Y)}\")\n",
    "print(f\"XとYの差集合: {set_X.difference(set_Y)}\")\n",
    "\n",
    "if len(set_X.intersection({\"se\"})):\n",
    "    print(\"seはXに含まれる\")\n",
    "else:\n",
    "    print(\"seはXに含まれない\")\n",
    "if len(set_Y.intersection({\"se\"})):\n",
    "    print(\"seはYに含まれる\")\n",
    "else:\n",
    "    print(\"seはYに含まれない\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 07. テンプレートによる文生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def gen_template_sentence(x, y, z):\n",
    "    print(f\"{x}時の{y}は{z}\")\n",
    "\n",
    "\n",
    "gen_template_sentence(x=12, y=\"気温\", z=22.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 08. 暗号文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nld I mvvw z wirmp, zoxlslorx lu xlfihv, zugvi gsv svzeb ovxgfivh rmeloermt jfzmgfn nvxszmrxh.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cipher(sentence):\n",
    "    p = re.compile('[a-z]')\n",
    "    sentence = [chr(219 - ord(s)) if p.fullmatch(s) else s for s in sentence]\n",
    "    return \"\".join(sentence)\n",
    "\n",
    "\n",
    "sentence = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "print(cipher(sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 09. Typoglycemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I c'oduntl bilev that I coudl aclluyt unsrtaedn what I was rdaiegn : the pnnmehealo pwore of the hamnu mind .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def Typoglycemia(sentence):\n",
    "\n",
    "    words_list = sentence.split(\" \")\n",
    "\n",
    "    for i in range(len(words_list)):\n",
    "        if len(words_list[i]) > 4:\n",
    "            word = words_list[i]\n",
    "            s = words_list[i][0]\n",
    "            e = words_list[i][-1]\n",
    "            word = word.replace(s, \"\").replace(e, \"\")\n",
    "            word = random.sample(word, len(word))\n",
    "            word.insert(0, s)\n",
    "            word.insert(-1, e)\n",
    "            words_list[i] = \"\".join(word)\n",
    "    sentence = \" \".join(words_list)\n",
    "    print(sentence)\n",
    "\n",
    "\n",
    "sentence = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "Typoglycemia(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
